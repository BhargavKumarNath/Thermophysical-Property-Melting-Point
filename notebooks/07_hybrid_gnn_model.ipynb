{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffd800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import RDLogger \n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, BatchNorm1d, Module, Sequential\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cbb8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Defining Data Processing for Hybrid Model ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Step 1: Defining Data Processing for Hybrid Model ---\")\n",
    "\n",
    "train_tabular = pd.read_csv('../data/processed/train_processed.csv')\n",
    "test_tabular = pd.read_csv('../data/processed/test_processed.csv')\n",
    "\n",
    "train_raw = pd.read_csv('../data/raw/train.csv')\n",
    "test_raw = pd.read_csv('../data/raw/test.csv')\n",
    "\n",
    "train_merged = pd.merge(train_raw[['id', 'SMILES']], train_tabular, on='id')\n",
    "test_merged = pd.merge(test_raw[['id', 'SMILES']], test_tabular, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f338b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdkit_features = [col for col in train_tabular.columns if not col.startswith('Group_') and col not in ['id', 'Tm']]\n",
    "X_train_rdkit = train_merged[rdkit_features]\n",
    "X_test_rdkit = test_merged[rdkit_features]\n",
    "\n",
    "rdkit_scaler = StandardScaler()\n",
    "X_train_rdkit_scaled = rdkit_scaler.fit_transform(X_train_rdkit)\n",
    "X_test_rdkit_scaled = rdkit_scaler.transform(X_test_rdkit)\n",
    "\n",
    "with open('../models/rdkit_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(rdkit_scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2ba21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_graph(smiles_string, y_val=0, rdkit_feats=None):\n",
    "    mol = Chem.MolFromSmiles(smiles_string)\n",
    "    if mol is None: return None\n",
    "    atom_features_list = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_features_list.append([\n",
    "            atom.GetAtomicNum(), atom.GetFormalCharge(), atom.GetHybridization(),\n",
    "            atom.GetIsAromatic(), atom.GetTotalNumHs(), atom.GetTotalValence(),\n",
    "        ])\n",
    "    x = torch.tensor(atom_features_list, dtype=torch.float)\n",
    "    edge_indices, edge_attrs = [], []\n",
    "    for bond in mol.GetBonds():\n",
    "        i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        bond_type = bond.GetBondTypeAsDouble()\n",
    "        edge_indices.extend([(i, j), (j, i)])\n",
    "        edge_attrs.extend([[bond_type], [bond_type]])\n",
    "    edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attrs, dtype=torch.float)\n",
    "    \n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=torch.tensor([y_val], dtype=torch.float))\n",
    "    if rdkit_feats is not None:\n",
    "        data.rdkit_features = torch.tensor([rdkit_feats], dtype=torch.float)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c588cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridDataset(Dataset):\n",
    "    def __init__(self, root, data_df, rdkit_features_scaled, test=False, node_feature_scaler=None):\n",
    "        self.data_df = data_df\n",
    "        self.rdkit_features_scaled = rdkit_features_scaled\n",
    "        self.test = test\n",
    "        self.node_feature_scaler = node_feature_scaler\n",
    "        super(HybridDataset, self).__init__(root)\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self): return []\n",
    "    @property\n",
    "    def processed_file_names(self): return [f'{\"test\" if self.test else \"train\"}_hybrid.pt']\n",
    "    def download(self): pass\n",
    "\n",
    "    def process(self):\n",
    "        if not self.test and self.node_feature_scaler is None:\n",
    "            all_node_features = []\n",
    "            for smiles in tqdm(self.data_df['SMILES'], desc=\"Fitting Node Scaler\"):\n",
    "                mol = Chem.MolFromSmiles(smiles)\n",
    "                if mol:\n",
    "                    for atom in mol.GetAtoms():\n",
    "                        all_node_features.append([atom.GetAtomicNum(), atom.GetFormalCharge(), atom.GetHybridization(), atom.GetIsAromatic(), atom.GetTotalNumHs(), atom.GetTotalValence()])\n",
    "            self.node_feature_scaler = StandardScaler()\n",
    "            self.node_feature_scaler.fit(all_node_features)\n",
    "            with open('../models/gnn_node_scaler.pkl', 'wb') as f:\n",
    "                pickle.dump(self.node_feature_scaler, f)\n",
    "\n",
    "        graphs = []\n",
    "        for idx, row in tqdm(self.data_df.iterrows(), total=self.data_df.shape[0], desc=\"Processing SMILES for Hybrid Model\"):\n",
    "            y_val = np.log(row['Tm']) if not self.test else 0\n",
    "            rdkit_feats = self.rdkit_features_scaled[idx]\n",
    "            graph = smiles_to_graph(row['SMILES'], y_val, rdkit_feats)\n",
    "            if graph is not None:\n",
    "                graph.x = torch.tensor(self.node_feature_scaler.transform(graph.x), dtype=torch.float)\n",
    "                graphs.append(graph)\n",
    "        torch.save(graphs, self.processed_paths[0], pickle_protocol=5)\n",
    "\n",
    "    def len(self):\n",
    "        if not hasattr(self, 'graphs'):\n",
    "            self.graphs = torch.load(self.processed_paths[0], weights_only=False)\n",
    "        return len(self.graphs)\n",
    "    def get(self, idx):\n",
    "        if not hasattr(self, 'graphs'):\n",
    "            self.graphs = torch.load(self.processed_paths[0], weights_only=False)\n",
    "        return self.graphs[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dd5e5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating Hybrid Datasets...\n",
      "Hybrid datasets created.\n"
     ]
    }
   ],
   "source": [
    "print(\"Instantiating Hybrid Datasets...\")\n",
    "train_dataset = HybridDataset(root='../data/processed/gnn_hybrid', data_df=train_merged, rdkit_features_scaled=X_train_rdkit_scaled)\n",
    "with open('../models/gnn_node_scaler.pkl', 'rb') as f:\n",
    "    node_scaler = pickle.load(f)\n",
    "test_dataset = HybridDataset(root='../data/processed/gnn_hybrid', data_df=test_merged, rdkit_features_scaled=X_test_rdkit_scaled, test=True, node_feature_scaler=node_scaler)\n",
    "print(\"Hybrid datasets created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2914b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 2: Defining the Hybrid GNN-MLP Architecture ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Step 2: Defining the Hybrid GNN-MLP Architecture ---\")\n",
    "\n",
    "class HybridGNN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_rdkit_features, hidden_channels=128):\n",
    "        super(HybridGNN, self).__init__()\n",
    "        torch.manual_seed(42)\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.bn1 = BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels * 2)\n",
    "        self.bn2 = BatchNorm1d(hidden_channels * 2)\n",
    "        \n",
    "        self.mlp = Sequential(\n",
    "            Linear(hidden_channels * 2 + num_rdkit_features, hidden_channels * 2), \n",
    "            torch.nn.ReLU(),\n",
    "            BatchNorm1d(hidden_channels * 2),\n",
    "            Linear(hidden_channels * 2, hidden_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            BatchNorm1d(hidden_channels),\n",
    "            Linear(hidden_channels, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch, rdkit_feats = data.x, data.edge_index, data.batch, data.rdkit_features\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.bn2(x)\n",
    "        graph_embedding = global_mean_pool(x, batch)\n",
    "        \n",
    "        combined_features = torch.cat([graph_embedding, rdkit_feats], dim=1)\n",
    "        \n",
    "        # Final prediction\n",
    "        return self.mlp(combined_features).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0ffe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 3: Starting Training for Hybrid Model ---\n"
     ]
    }
   ],
   "source": [
    "# 3. Training and Submission\n",
    "print(\"\\n--- Step 3: Starting Training for Hybrid Model ---\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "shuffled_dataset = train_dataset.shuffle()\n",
    "train_size = int(0.85 * len(shuffled_dataset))\n",
    "train_data, val_data = shuffled_dataset[:train_size], shuffled_dataset[train_size:]\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "\n",
    "model = HybridGNN(\n",
    "    num_node_features=train_dataset.num_node_features,\n",
    "    num_rdkit_features=X_train_rdkit_scaled.shape[1]\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=10, min_lr=1e-6)\n",
    "criterion = torch.nn.L1Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b35c67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 1.6701, Val MAE: 4.1654, Best Val MAE: 4.1654, LR: 0.000500\n",
      "Epoch: 002, Loss: 1.4916, Val MAE: 3.4177, Best Val MAE: 3.4177, LR: 0.000500\n",
      "Epoch: 003, Loss: 1.2116, Val MAE: 3.0102, Best Val MAE: 3.0102, LR: 0.000500\n",
      "Epoch: 004, Loss: 0.8253, Val MAE: 2.0039, Best Val MAE: 2.0039, LR: 0.000500\n",
      "Epoch: 005, Loss: 0.3889, Val MAE: 2.1052, Best Val MAE: 2.0039, LR: 0.000500\n",
      "Epoch: 006, Loss: 0.1702, Val MAE: 1.1064, Best Val MAE: 1.1064, LR: 0.000500\n",
      "Epoch: 007, Loss: 0.1322, Val MAE: 0.6878, Best Val MAE: 0.6878, LR: 0.000500\n",
      "Epoch: 008, Loss: 0.0946, Val MAE: 0.5350, Best Val MAE: 0.5350, LR: 0.000500\n",
      "Epoch: 009, Loss: 0.0810, Val MAE: 0.2969, Best Val MAE: 0.2969, LR: 0.000500\n",
      "Epoch: 010, Loss: 0.0631, Val MAE: 0.2883, Best Val MAE: 0.2883, LR: 0.000500\n",
      "Epoch: 011, Loss: 0.0538, Val MAE: 0.2656, Best Val MAE: 0.2656, LR: 0.000500\n",
      "Epoch: 012, Loss: 0.0521, Val MAE: 0.3248, Best Val MAE: 0.2656, LR: 0.000500\n",
      "Epoch: 013, Loss: 0.0534, Val MAE: 0.2139, Best Val MAE: 0.2139, LR: 0.000500\n",
      "Epoch: 014, Loss: 0.0464, Val MAE: 0.2670, Best Val MAE: 0.2139, LR: 0.000500\n",
      "Epoch: 015, Loss: 0.0497, Val MAE: 0.2285, Best Val MAE: 0.2139, LR: 0.000500\n",
      "Epoch: 016, Loss: 0.0505, Val MAE: 0.2307, Best Val MAE: 0.2139, LR: 0.000500\n",
      "Epoch: 017, Loss: 0.0398, Val MAE: 0.3151, Best Val MAE: 0.2139, LR: 0.000500\n",
      "Epoch: 018, Loss: 0.0448, Val MAE: 0.3476, Best Val MAE: 0.2139, LR: 0.000500\n",
      "Epoch: 019, Loss: 0.0435, Val MAE: 0.2524, Best Val MAE: 0.2139, LR: 0.000500\n",
      "Epoch: 020, Loss: 0.0403, Val MAE: 0.2640, Best Val MAE: 0.2139, LR: 0.000500\n",
      "Epoch: 021, Loss: 0.0439, Val MAE: 0.2338, Best Val MAE: 0.2139, LR: 0.000500\n",
      "Epoch: 022, Loss: 0.0419, Val MAE: 0.2820, Best Val MAE: 0.2139, LR: 0.000500\n",
      "Epoch: 023, Loss: 0.0360, Val MAE: 0.3007, Best Val MAE: 0.2139, LR: 0.000500\n",
      "Epoch: 024, Loss: 0.0368, Val MAE: 0.2647, Best Val MAE: 0.2139, LR: 0.000350\n",
      "Epoch: 025, Loss: 0.0365, Val MAE: 0.1698, Best Val MAE: 0.1698, LR: 0.000350\n",
      "Epoch: 026, Loss: 0.0310, Val MAE: 0.1909, Best Val MAE: 0.1698, LR: 0.000350\n",
      "Epoch: 027, Loss: 0.0326, Val MAE: 0.2132, Best Val MAE: 0.1698, LR: 0.000350\n",
      "Epoch: 028, Loss: 0.0333, Val MAE: 0.1945, Best Val MAE: 0.1698, LR: 0.000350\n",
      "Epoch: 029, Loss: 0.0302, Val MAE: 0.1727, Best Val MAE: 0.1698, LR: 0.000350\n",
      "Epoch: 030, Loss: 0.0310, Val MAE: 0.1523, Best Val MAE: 0.1523, LR: 0.000350\n",
      "Epoch: 031, Loss: 0.0273, Val MAE: 0.1499, Best Val MAE: 0.1499, LR: 0.000350\n",
      "Epoch: 032, Loss: 0.0322, Val MAE: 0.1441, Best Val MAE: 0.1441, LR: 0.000350\n",
      "Epoch: 033, Loss: 0.0276, Val MAE: 0.2887, Best Val MAE: 0.1441, LR: 0.000350\n",
      "Epoch: 034, Loss: 0.0316, Val MAE: 0.1633, Best Val MAE: 0.1441, LR: 0.000350\n",
      "Epoch: 035, Loss: 0.0278, Val MAE: 0.2184, Best Val MAE: 0.1441, LR: 0.000350\n",
      "Epoch: 036, Loss: 0.0323, Val MAE: 0.1706, Best Val MAE: 0.1441, LR: 0.000350\n",
      "Epoch: 037, Loss: 0.0326, Val MAE: 0.1717, Best Val MAE: 0.1441, LR: 0.000350\n",
      "Epoch: 038, Loss: 0.0272, Val MAE: 0.1584, Best Val MAE: 0.1441, LR: 0.000350\n",
      "Epoch: 039, Loss: 0.0290, Val MAE: 0.1524, Best Val MAE: 0.1441, LR: 0.000350\n",
      "Epoch: 040, Loss: 0.0261, Val MAE: 0.1633, Best Val MAE: 0.1441, LR: 0.000350\n",
      "Epoch: 041, Loss: 0.0286, Val MAE: 0.1556, Best Val MAE: 0.1441, LR: 0.000350\n",
      "Epoch: 042, Loss: 0.0257, Val MAE: 0.1461, Best Val MAE: 0.1441, LR: 0.000350\n",
      "Epoch: 043, Loss: 0.0264, Val MAE: 0.1489, Best Val MAE: 0.1441, LR: 0.000245\n",
      "Epoch: 044, Loss: 0.0290, Val MAE: 0.1378, Best Val MAE: 0.1378, LR: 0.000245\n",
      "Epoch: 045, Loss: 0.0257, Val MAE: 0.1690, Best Val MAE: 0.1378, LR: 0.000245\n",
      "Epoch: 046, Loss: 0.0305, Val MAE: 0.1606, Best Val MAE: 0.1378, LR: 0.000245\n",
      "Epoch: 047, Loss: 0.0243, Val MAE: 0.1639, Best Val MAE: 0.1378, LR: 0.000245\n",
      "Epoch: 048, Loss: 0.0245, Val MAE: 0.1358, Best Val MAE: 0.1358, LR: 0.000245\n",
      "Epoch: 049, Loss: 0.0240, Val MAE: 0.1225, Best Val MAE: 0.1225, LR: 0.000245\n",
      "Epoch: 050, Loss: 0.0234, Val MAE: 0.1456, Best Val MAE: 0.1225, LR: 0.000245\n",
      "Epoch: 051, Loss: 0.0238, Val MAE: 0.1340, Best Val MAE: 0.1225, LR: 0.000245\n",
      "Epoch: 052, Loss: 0.0219, Val MAE: 0.1360, Best Val MAE: 0.1225, LR: 0.000245\n",
      "Epoch: 053, Loss: 0.0212, Val MAE: 0.1359, Best Val MAE: 0.1225, LR: 0.000245\n",
      "Epoch: 054, Loss: 0.0264, Val MAE: 0.1727, Best Val MAE: 0.1225, LR: 0.000245\n",
      "Epoch: 055, Loss: 0.0293, Val MAE: 0.1467, Best Val MAE: 0.1225, LR: 0.000245\n",
      "Epoch: 056, Loss: 0.0216, Val MAE: 0.1442, Best Val MAE: 0.1225, LR: 0.000245\n",
      "Epoch: 057, Loss: 0.0234, Val MAE: 0.1806, Best Val MAE: 0.1225, LR: 0.000245\n",
      "Epoch: 058, Loss: 0.0223, Val MAE: 0.1658, Best Val MAE: 0.1225, LR: 0.000245\n",
      "Epoch: 059, Loss: 0.0224, Val MAE: 0.1478, Best Val MAE: 0.1225, LR: 0.000245\n",
      "Epoch: 060, Loss: 0.0233, Val MAE: 0.1387, Best Val MAE: 0.1225, LR: 0.000171\n",
      "Epoch: 061, Loss: 0.0221, Val MAE: 0.1336, Best Val MAE: 0.1225, LR: 0.000171\n",
      "Epoch: 062, Loss: 0.0202, Val MAE: 0.1558, Best Val MAE: 0.1225, LR: 0.000171\n",
      "Epoch: 063, Loss: 0.0220, Val MAE: 0.1220, Best Val MAE: 0.1220, LR: 0.000171\n",
      "Epoch: 064, Loss: 0.0238, Val MAE: 0.1655, Best Val MAE: 0.1220, LR: 0.000171\n",
      "Epoch: 065, Loss: 0.0212, Val MAE: 0.1301, Best Val MAE: 0.1220, LR: 0.000171\n",
      "Epoch: 066, Loss: 0.0209, Val MAE: 0.1377, Best Val MAE: 0.1220, LR: 0.000171\n",
      "Epoch: 067, Loss: 0.0196, Val MAE: 0.1259, Best Val MAE: 0.1220, LR: 0.000171\n",
      "Epoch: 068, Loss: 0.0189, Val MAE: 0.1440, Best Val MAE: 0.1220, LR: 0.000171\n",
      "Epoch: 069, Loss: 0.0199, Val MAE: 0.1156, Best Val MAE: 0.1156, LR: 0.000171\n",
      "Epoch: 070, Loss: 0.0207, Val MAE: 0.1250, Best Val MAE: 0.1156, LR: 0.000171\n",
      "Epoch: 071, Loss: 0.0205, Val MAE: 0.1235, Best Val MAE: 0.1156, LR: 0.000171\n",
      "Epoch: 072, Loss: 0.0218, Val MAE: 0.1194, Best Val MAE: 0.1156, LR: 0.000171\n",
      "Epoch: 073, Loss: 0.0211, Val MAE: 0.1283, Best Val MAE: 0.1156, LR: 0.000171\n",
      "Epoch: 074, Loss: 0.0200, Val MAE: 0.1234, Best Val MAE: 0.1156, LR: 0.000171\n",
      "Epoch: 075, Loss: 0.0197, Val MAE: 0.1171, Best Val MAE: 0.1156, LR: 0.000171\n",
      "Epoch: 076, Loss: 0.0211, Val MAE: 0.1487, Best Val MAE: 0.1156, LR: 0.000171\n",
      "Epoch: 077, Loss: 0.0215, Val MAE: 0.1429, Best Val MAE: 0.1156, LR: 0.000171\n",
      "Epoch: 078, Loss: 0.0217, Val MAE: 0.1315, Best Val MAE: 0.1156, LR: 0.000171\n",
      "Epoch: 079, Loss: 0.0213, Val MAE: 0.1100, Best Val MAE: 0.1100, LR: 0.000171\n",
      "Epoch: 080, Loss: 0.0210, Val MAE: 0.1367, Best Val MAE: 0.1100, LR: 0.000171\n",
      "Epoch: 081, Loss: 0.0192, Val MAE: 0.1534, Best Val MAE: 0.1100, LR: 0.000171\n",
      "Epoch: 082, Loss: 0.0211, Val MAE: 0.1167, Best Val MAE: 0.1100, LR: 0.000171\n",
      "Epoch: 083, Loss: 0.0199, Val MAE: 0.1211, Best Val MAE: 0.1100, LR: 0.000171\n",
      "Epoch: 084, Loss: 0.0181, Val MAE: 0.1147, Best Val MAE: 0.1100, LR: 0.000171\n",
      "Epoch: 085, Loss: 0.0198, Val MAE: 0.1188, Best Val MAE: 0.1100, LR: 0.000171\n",
      "Epoch: 086, Loss: 0.0183, Val MAE: 0.1254, Best Val MAE: 0.1100, LR: 0.000171\n",
      "Epoch: 087, Loss: 0.0193, Val MAE: 0.1271, Best Val MAE: 0.1100, LR: 0.000171\n",
      "Epoch: 088, Loss: 0.0194, Val MAE: 0.1365, Best Val MAE: 0.1100, LR: 0.000171\n",
      "Epoch: 089, Loss: 0.0194, Val MAE: 0.1314, Best Val MAE: 0.1100, LR: 0.000171\n",
      "Epoch: 090, Loss: 0.0192, Val MAE: 0.1289, Best Val MAE: 0.1100, LR: 0.000120\n",
      "Epoch: 091, Loss: 0.0192, Val MAE: 0.1597, Best Val MAE: 0.1100, LR: 0.000120\n",
      "Epoch: 092, Loss: 0.0204, Val MAE: 0.1096, Best Val MAE: 0.1096, LR: 0.000120\n",
      "Epoch: 093, Loss: 0.0164, Val MAE: 0.1121, Best Val MAE: 0.1096, LR: 0.000120\n",
      "Epoch: 094, Loss: 0.0175, Val MAE: 0.1118, Best Val MAE: 0.1096, LR: 0.000120\n",
      "Epoch: 095, Loss: 0.0169, Val MAE: 0.1188, Best Val MAE: 0.1096, LR: 0.000120\n",
      "Epoch: 096, Loss: 0.0175, Val MAE: 0.1160, Best Val MAE: 0.1096, LR: 0.000120\n",
      "Epoch: 097, Loss: 0.0173, Val MAE: 0.1216, Best Val MAE: 0.1096, LR: 0.000120\n",
      "Epoch: 098, Loss: 0.0178, Val MAE: 0.1155, Best Val MAE: 0.1096, LR: 0.000120\n",
      "Epoch: 099, Loss: 0.0182, Val MAE: 0.1282, Best Val MAE: 0.1096, LR: 0.000120\n",
      "Epoch: 100, Loss: 0.0192, Val MAE: 0.1215, Best Val MAE: 0.1096, LR: 0.000120\n",
      "Epoch: 101, Loss: 0.0192, Val MAE: 0.1136, Best Val MAE: 0.1096, LR: 0.000120\n",
      "Epoch: 102, Loss: 0.0176, Val MAE: 0.1363, Best Val MAE: 0.1096, LR: 0.000120\n",
      "Epoch: 103, Loss: 0.0170, Val MAE: 0.1103, Best Val MAE: 0.1096, LR: 0.000084\n",
      "Epoch: 104, Loss: 0.0162, Val MAE: 0.1290, Best Val MAE: 0.1096, LR: 0.000084\n",
      "Epoch: 105, Loss: 0.0170, Val MAE: 0.1085, Best Val MAE: 0.1085, LR: 0.000084\n",
      "Epoch: 106, Loss: 0.0166, Val MAE: 0.1109, Best Val MAE: 0.1085, LR: 0.000084\n",
      "Epoch: 107, Loss: 0.0161, Val MAE: 0.1140, Best Val MAE: 0.1085, LR: 0.000084\n",
      "Epoch: 108, Loss: 0.0168, Val MAE: 0.1241, Best Val MAE: 0.1085, LR: 0.000084\n",
      "Epoch: 109, Loss: 0.0168, Val MAE: 0.1062, Best Val MAE: 0.1062, LR: 0.000084\n",
      "Epoch: 110, Loss: 0.0161, Val MAE: 0.1166, Best Val MAE: 0.1062, LR: 0.000084\n",
      "Epoch: 111, Loss: 0.0152, Val MAE: 0.1196, Best Val MAE: 0.1062, LR: 0.000084\n",
      "Epoch: 112, Loss: 0.0170, Val MAE: 0.1108, Best Val MAE: 0.1062, LR: 0.000084\n",
      "Epoch: 113, Loss: 0.0150, Val MAE: 0.1069, Best Val MAE: 0.1062, LR: 0.000084\n",
      "Epoch: 114, Loss: 0.0156, Val MAE: 0.1104, Best Val MAE: 0.1062, LR: 0.000084\n",
      "Epoch: 115, Loss: 0.0169, Val MAE: 0.1011, Best Val MAE: 0.1011, LR: 0.000084\n",
      "Epoch: 116, Loss: 0.0161, Val MAE: 0.1108, Best Val MAE: 0.1011, LR: 0.000084\n",
      "Epoch: 117, Loss: 0.0164, Val MAE: 0.1043, Best Val MAE: 0.1011, LR: 0.000084\n",
      "Epoch: 118, Loss: 0.0161, Val MAE: 0.1133, Best Val MAE: 0.1011, LR: 0.000084\n",
      "Epoch: 119, Loss: 0.0171, Val MAE: 0.1128, Best Val MAE: 0.1011, LR: 0.000084\n",
      "Epoch: 120, Loss: 0.0175, Val MAE: 0.1080, Best Val MAE: 0.1011, LR: 0.000084\n",
      "Epoch: 121, Loss: 0.0160, Val MAE: 0.1093, Best Val MAE: 0.1011, LR: 0.000084\n",
      "Epoch: 122, Loss: 0.0161, Val MAE: 0.1118, Best Val MAE: 0.1011, LR: 0.000084\n",
      "Epoch: 123, Loss: 0.0160, Val MAE: 0.1303, Best Val MAE: 0.1011, LR: 0.000084\n",
      "Epoch: 124, Loss: 0.0160, Val MAE: 0.1193, Best Val MAE: 0.1011, LR: 0.000084\n",
      "Epoch: 125, Loss: 0.0156, Val MAE: 0.1234, Best Val MAE: 0.1011, LR: 0.000084\n",
      "Epoch: 126, Loss: 0.0163, Val MAE: 0.1144, Best Val MAE: 0.1011, LR: 0.000059\n",
      "Epoch: 127, Loss: 0.0166, Val MAE: 0.1238, Best Val MAE: 0.1011, LR: 0.000059\n",
      "Epoch: 128, Loss: 0.0164, Val MAE: 0.1131, Best Val MAE: 0.1011, LR: 0.000059\n",
      "Epoch: 129, Loss: 0.0145, Val MAE: 0.1121, Best Val MAE: 0.1011, LR: 0.000059\n",
      "Epoch: 130, Loss: 0.0156, Val MAE: 0.1037, Best Val MAE: 0.1011, LR: 0.000059\n",
      "Epoch: 131, Loss: 0.0154, Val MAE: 0.1095, Best Val MAE: 0.1011, LR: 0.000059\n",
      "Epoch: 132, Loss: 0.0142, Val MAE: 0.1197, Best Val MAE: 0.1011, LR: 0.000059\n",
      "Epoch: 133, Loss: 0.0163, Val MAE: 0.1086, Best Val MAE: 0.1011, LR: 0.000059\n",
      "Epoch: 134, Loss: 0.0154, Val MAE: 0.1120, Best Val MAE: 0.1011, LR: 0.000059\n",
      "Epoch: 135, Loss: 0.0151, Val MAE: 0.1053, Best Val MAE: 0.1011, LR: 0.000059\n",
      "Epoch: 136, Loss: 0.0150, Val MAE: 0.1051, Best Val MAE: 0.1011, LR: 0.000059\n",
      "Epoch: 137, Loss: 0.0149, Val MAE: 0.1207, Best Val MAE: 0.1011, LR: 0.000041\n",
      "Epoch: 138, Loss: 0.0158, Val MAE: 0.1164, Best Val MAE: 0.1011, LR: 0.000041\n",
      "Epoch: 139, Loss: 0.0146, Val MAE: 0.1112, Best Val MAE: 0.1011, LR: 0.000041\n",
      "Epoch: 140, Loss: 0.0143, Val MAE: 0.1021, Best Val MAE: 0.1011, LR: 0.000041\n",
      "Early stopping at epoch 140.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def evaluate(loader):\n",
    "    \"\"\"Evaluates the model on a given data loader.\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_reals = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            preds = np.exp(out.cpu().numpy())\n",
    "            reals = np.exp(data.y.cpu().numpy())\n",
    "            all_preds.extend(preds)\n",
    "            all_reals.extend(reals)\n",
    "            \n",
    "    return mean_absolute_error(all_reals, all_preds)\n",
    "\n",
    "\n",
    "\n",
    "best_val_mae = float('inf')\n",
    "patience_counter = 0\n",
    "patience = 25\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    val_mae = evaluate(val_loader)\n",
    "    scheduler.step(val_mae)\n",
    "    \n",
    "    if val_mae < best_val_mae:\n",
    "        best_val_mae = val_mae\n",
    "        torch.save(model.state_dict(), 'best_hybrid_model.pt')\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        \n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val MAE: {val_mae:.4f}, Best Val MAE: {best_val_mae:.4f}, LR: {lr:.6f}')\n",
    "        \n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch}.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "725b447e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Final Submission from Hybrid Model ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc44bca00864812b5f96b83a5737415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting with Hybrid Model:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file 'submission_hybrid_gnn.csv' created successfully!\n",
      "     id        Tm\n",
      "0  1022  5.828165\n",
      "1  1146  5.736335\n",
      "2    79  5.263012\n",
      "3  2279  5.352048\n",
      "4  1342  5.469879\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Generating Final Submission from Hybrid Model ---\")\n",
    "model.load_state_dict(torch.load('best_hybrid_model.pt'))\n",
    "test_preds = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(test_loader, desc=\"Predicting with Hybrid Model\"):\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        test_preds.extend(np.exp(out.cpu().numpy()))\n",
    "\n",
    "submission_df = pd.read_csv('../data/raw/sample_submission.csv')\n",
    "submission_df['Tm'] = test_preds\n",
    "submission_df.to_csv('submission_hybrid_gnn.csv', index=False)\n",
    "print(\"Submission file 'submission_hybrid_gnn.csv' created successfully!\")\n",
    "print(submission_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0314b4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
