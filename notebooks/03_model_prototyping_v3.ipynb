{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d758fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.base import clone\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b0f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_torch_cuda():\n",
    "    try:\n",
    "        import torch\n",
    "        return torch.cuda.is_available()\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def get_nvidia_gpu_free_memory_mb():\n",
    "    try:\n",
    "        import pynvml\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "        info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        free_mb = info.free // (1024 * 1024)\n",
    "        total_mb = info.total // (1024 * 1024)\n",
    "        pynvml.nvmlShutdown()\n",
    "        return free_mb, total_mb\n",
    "    except Exception:\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c8ac318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Project\\Thermophysical Property Melting Point\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU] Free memory detected: 7948 MB / 8188 MB\n",
      "CATBOOST_USE_GPU=True, LIGHTGBM_GPU=True, XGBOOST_GPU=True\n"
     ]
    }
   ],
   "source": [
    "GPU_AVAILABLE = has_torch_cuda()\n",
    "FREE_GPU_MB, TOTAL_GPU_MB = get_nvidia_gpu_free_memory_mb()\n",
    "if FREE_GPU_MB is not None:\n",
    "    print(f\"[GPU] Free memory detected: {FREE_GPU_MB} MB / {TOTAL_GPU_MB} MB\")\n",
    "else:\n",
    "    print(f\"[GPU] Could not detect GPU memory via pynvml. Torch reports CUDA available: {GPU_AVAILABLE}\")\n",
    "\n",
    "CATBOOST_GPU_MIN_MB = 6000  \n",
    "CATBOOST_USE_GPU = False\n",
    "if GPU_AVAILABLE and FREE_GPU_MB is not None and FREE_GPU_MB >= CATBOOST_GPU_MIN_MB:\n",
    "    CATBOOST_USE_GPU = True\n",
    "elif GPU_AVAILABLE and FREE_GPU_MB is None:\n",
    "    CATBOOST_USE_GPU = True\n",
    "\n",
    "USE_GPU_FOR_LIGHTGBM = GPU_AVAILABLE\n",
    "USE_GPU_FOR_XGBOOST = GPU_AVAILABLE\n",
    "\n",
    "print(f\"CATBOOST_USE_GPU={CATBOOST_USE_GPU}, LIGHTGBM_GPU={USE_GPU_FOR_LIGHTGBM}, XGBOOST_GPU={USE_GPU_FOR_XGBOOST}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a780c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_SPLITS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Keep features manageable\n",
    "TOP_K_FEATURES = 2000\n",
    "\n",
    "LGB_PARAMS = {\n",
    "    'n_estimators': 400,\n",
    "    'learning_rate': 0.03,\n",
    "    'max_depth': 10,\n",
    "    'n_jobs': -1,\n",
    "    'verbose': -1,\n",
    "    'device_type': 'gpu' if USE_GPU_FOR_LIGHTGBM else 'cpu',\n",
    "}\n",
    "\n",
    "XGB_PARAMS = {\n",
    "    'n_estimators': 400,\n",
    "    'learning_rate': 0.03,\n",
    "    'max_depth': 8,\n",
    "    'tree_method': 'hist',\n",
    "    'verbosity': 0,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'n_jobs': -1,\n",
    "    'device': 'cuda' if USE_GPU_FOR_XGBOOST else 'cpu'\n",
    "}\n",
    "\n",
    "CAT_PARAMS = {\n",
    "    'iterations': 500,\n",
    "    'learning_rate': 0.03,\n",
    "    'depth': 8,\n",
    "    'verbose': 100,\n",
    "}\n",
    "\n",
    "if not CATBOOST_USE_GPU:\n",
    "    CAT_PARAMS['iterations'] = 250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6880c853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train/test\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/processed/train_processed.csv')\n",
    "test_df = pd.read_csv('../data/processed/test_processed.csv')\n",
    "\n",
    "print(\"Loaded train/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b135990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial numeric feature count: 322\n"
     ]
    }
   ],
   "source": [
    "features = [c for c in test_df.columns if c not in ['id', 'SMILES']]\n",
    "X = train_df[features].copy()\n",
    "y = train_df['Tm'].copy()\n",
    "\n",
    "X = X.copy()\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n",
    "\n",
    "X.columns = [c.strip().replace(' ', '_') for c in X.columns]\n",
    "\n",
    "print(f\"Initial numeric feature count: {X.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfdca613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After variance thresholding: 307 features remain\n",
      "Using 307 features for modeling\n"
     ]
    }
   ],
   "source": [
    "vt = VarianceThreshold(threshold=1e-8)\n",
    "try:\n",
    "    X = pd.DataFrame(vt.fit_transform(X), columns=[c for i,c in enumerate(X.columns) if vt.get_support()[i]])\n",
    "    print(f\"After variance thresholding: {X.shape[1]} features remain\")\n",
    "except Exception:\n",
    "    X = X.select_dtypes(include=[np.number])\n",
    "    print(f\"After forcing numeric selection: {X.shape[1]} features remain\")\n",
    "\n",
    "def select_top_k_by_corr(X_df, y_series, k=TOP_K_FEATURES):\n",
    "    numeric = X_df.select_dtypes(include=[np.number]).columns\n",
    "    cors = {}\n",
    "    for c in numeric:\n",
    "        col = X_df[c].values\n",
    "        if np.nanstd(col) == 0:\n",
    "            continue\n",
    "        corr = np.corrcoef(col, y_series.values)[0,1]\n",
    "        if np.isfinite(corr):\n",
    "            cors[c] = abs(corr)\n",
    "    if not cors:\n",
    "        return X_df\n",
    "    sel = sorted(cors.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "    cols = [c for c, _ in sel]\n",
    "    return X_df[cols]\n",
    "\n",
    "if X.shape[1] > TOP_K_FEATURES:\n",
    "    X = select_top_k_by_corr(X, y, k=TOP_K_FEATURES)\n",
    "    print(f\"Selected top {X.shape[1]} features by correlation\")\n",
    "\n",
    "print(f\"Using {X.shape[1]} features for modeling\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe64b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TARGET: Using pre-transformed 'y' for training.\n"
     ]
    }
   ],
   "source": [
    "# Reset indices for safe iloc slicing\n",
    "X = X.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "print(\" TARGET: Using pre-transformed 'y' for training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057ce7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "results = {}\n",
    "\n",
    "def evaluate_model_cv(name, model, scale=False, lgb_params=None, xgb_params=None, cat_params=None):\n",
    "    \"\"\"\n",
    "    Evaluates a model using cross-validation.\n",
    "    Assumes the target 'y' is already log-transformed.\n",
    "    Calculates MAE on the original (Kelvin) scale.\n",
    "    \"\"\"\n",
    "    mae_list = []\n",
    "    steps = []\n",
    "    if scale:\n",
    "        steps.append(('scaler', StandardScaler()))\n",
    "    steps.append(('model', model))\n",
    "    pipe = Pipeline(steps)\n",
    "    \n",
    "    it = tqdm(kf.split(X, y), total=kf.get_n_splits(), desc=f'Training {name}', leave=True)\n",
    "    for fold_idx, (tr_idx, val_idx) in enumerate(it):\n",
    "        model = clone(model)\n",
    "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "\n",
    "        if name == 'LightGBM' and isinstance(model, lgb.LGBMRegressor):\n",
    "            model.set_params(**(lgb_params or {}))\n",
    "            model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "            y_pred_log = model.predict(X_val, num_iteration=model.best_iteration_)\n",
    "        elif name == 'XGBoost' and isinstance(model, xgb.XGBRegressor):\n",
    "            model.set_params(**(xgb_params or {}))\n",
    "            model.fit(X_tr, y_tr)\n",
    "            y_pred_log = model.predict(X_val)\n",
    "        elif name == 'CatBoost' and isinstance(model, CatBoostRegressor):\n",
    "            model.set_params(**(cat_params or {}))\n",
    "            model.fit(X_tr, y_tr, eval_set=(X_val, y_val), use_best_model=True, verbose=cat_params.get('verbose', False))\n",
    "            y_pred_log = model.predict(X_val)\n",
    "        else:\n",
    "            pipe.fit(X_tr, y_tr)\n",
    "            y_pred_log = pipe.predict(X_val)\n",
    "\n",
    "        if np.any(np.isnan(y_pred_log)):\n",
    "            y_pred_log = np.nan_to_num(y_pred_log, nan=np.nanmedian(y_pred_log))\n",
    "            \n",
    "        # Convert true values and predictions back to original Kelvin scale for MAE calculation\n",
    "        true_kelvin = np.exp(y_val.values)\n",
    "        pred_kelvin = np.exp(y_pred_log)\n",
    "\n",
    "        mae = mean_absolute_error(true_kelvin, pred_kelvin)\n",
    "        mae_list.append(mae)\n",
    "        it.set_postfix_str(f\"fold {fold_idx+1} mae {mae:.3f} K\")\n",
    "        print(f\"{name} Fold {fold_idx+1} MAE: {mae:.3f} K\")\n",
    "\n",
    "    mean_mae = np.mean(mae_list)\n",
    "    std_mae = np.std(mae_list)\n",
    "    results[name] = {'mean_mae': mean_mae, 'std_mae': std_mae}\n",
    "    print(f\"{name} - Average MAE: {mean_mae:.3f} +/- {std_mae:.3f} K\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c27648d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('Ridge', Ridge(alpha=1.0, random_state=RANDOM_STATE), True, {}),\n",
    "    ('ElasticNet', ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=RANDOM_STATE), True, {}),\n",
    "    ('RandomForest', RandomForestRegressor(n_estimators=200, max_depth=12, random_state=RANDOM_STATE, n_jobs=-1), False, {}),\n",
    "    ('HistGB', HistGradientBoostingRegressor(max_iter=300, max_depth=10, random_state=RANDOM_STATE), False, {}),\n",
    "\n",
    "    ('LightGBM', lgb.LGBMRegressor(**LGB_PARAMS), False, LGB_PARAMS),\n",
    "\n",
    "    ('XGBoost', xgb.XGBRegressor(**XGB_PARAMS), False, XGB_PARAMS),\n",
    "\n",
    "    ('CatBoost', CatBoostRegressor(task_type='GPU' if CATBOOST_USE_GPU else 'CPU', devices='0' if CATBOOST_USE_GPU else None,\n",
    "                                  iterations=CAT_PARAMS['iterations'],\n",
    "                                  learning_rate=CAT_PARAMS['learning_rate'],\n",
    "                                  depth=CAT_PARAMS['depth'],\n",
    "                                  random_seed=RANDOM_STATE,\n",
    "                                  verbose=CAT_PARAMS.get('verbose', 100),\n",
    "                                  allow_writing_files=False),\n",
    "     False, CAT_PARAMS),\n",
    "\n",
    "    ('KNN', KNeighborsRegressor(n_neighbors=5, n_jobs=-1), True, {}),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c82a5366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluating: Ridge ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Ridge:   0%|          | 0/5 [00:00<?, ?it/s, fold 3 mae 32.669 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Fold 1 MAE: 35.860 K\n",
      "Ridge Fold 2 MAE: 32.662 K\n",
      "Ridge Fold 3 MAE: 32.669 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Ridge: 100%|██████████| 5/5 [00:00<00:00, 46.84it/s, fold 5 mae 36.343 K]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Fold 4 MAE: 35.291 K\n",
      "Ridge Fold 5 MAE: 36.343 K\n",
      "Ridge - Average MAE: 34.565 +/- 1.586 K\n",
      "\n",
      "=== Evaluating: ElasticNet ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training ElasticNet:   0%|          | 0/5 [00:00<?, ?it/s, fold 1 mae 49.524 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet Fold 1 MAE: 49.524 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training ElasticNet:   0%|          | 0/5 [00:00<?, ?it/s, fold 2 mae 45.071 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet Fold 2 MAE: 45.071 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training ElasticNet:   0%|          | 0/5 [00:00<?, ?it/s, fold 3 mae 46.303 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet Fold 3 MAE: 46.303 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training ElasticNet: 100%|██████████| 5/5 [00:00<00:00, 44.17it/s, fold 5 mae 45.734 K]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet Fold 4 MAE: 49.057 K\n",
      "ElasticNet Fold 5 MAE: 45.734 K\n",
      "ElasticNet - Average MAE: 47.138 +/- 1.806 K\n",
      "\n",
      "=== Evaluating: RandomForest ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training RandomForest:  20%|██        | 1/5 [00:01<00:05,  1.38s/it, fold 1 mae 31.415 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Fold 1 MAE: 31.415 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training RandomForest:  40%|████      | 2/5 [00:02<00:04,  1.43s/it, fold 2 mae 30.536 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Fold 2 MAE: 30.536 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training RandomForest:  60%|██████    | 3/5 [00:04<00:02,  1.37s/it, fold 3 mae 30.230 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Fold 3 MAE: 30.230 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training RandomForest:  80%|████████  | 4/5 [00:05<00:01,  1.36s/it, fold 4 mae 32.172 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Fold 4 MAE: 32.172 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training RandomForest: 100%|██████████| 5/5 [00:06<00:00,  1.38s/it, fold 5 mae 30.621 K]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Fold 5 MAE: 30.621 K\n",
      "RandomForest - Average MAE: 30.995 +/- 0.707 K\n",
      "\n",
      "=== Evaluating: HistGB ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training HistGB:  20%|██        | 1/5 [00:03<00:14,  3.67s/it, fold 1 mae 28.870 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGB Fold 1 MAE: 28.870 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training HistGB:  40%|████      | 2/5 [00:05<00:08,  2.84s/it, fold 2 mae 27.767 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGB Fold 2 MAE: 27.767 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training HistGB:  60%|██████    | 3/5 [00:08<00:05,  2.60s/it, fold 3 mae 27.929 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGB Fold 3 MAE: 27.929 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training HistGB:  80%|████████  | 4/5 [00:10<00:02,  2.46s/it, fold 4 mae 28.529 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGB Fold 4 MAE: 28.529 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training HistGB: 100%|██████████| 5/5 [00:12<00:00,  2.56s/it, fold 5 mae 28.281 K]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGB Fold 5 MAE: 28.281 K\n",
      "HistGB - Average MAE: 28.275 +/- 0.399 K\n",
      "\n",
      "=== Evaluating: LightGBM ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM:  20%|██        | 1/5 [00:03<00:12,  3.21s/it, fold 1 mae 28.640 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Fold 1 MAE: 28.640 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM:  40%|████      | 2/5 [00:05<00:08,  2.75s/it, fold 2 mae 27.884 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Fold 2 MAE: 27.884 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM:  60%|██████    | 3/5 [00:08<00:05,  2.60s/it, fold 3 mae 27.855 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Fold 3 MAE: 27.855 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM:  80%|████████  | 4/5 [00:10<00:02,  2.60s/it, fold 4 mae 28.967 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Fold 4 MAE: 28.967 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM: 100%|██████████| 5/5 [00:13<00:00,  2.62s/it, fold 5 mae 27.591 K]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Fold 5 MAE: 27.591 K\n",
      "LightGBM - Average MAE: 28.187 +/- 0.524 K\n",
      "\n",
      "=== Evaluating: XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training XGBoost:  20%|██        | 1/5 [00:02<00:11,  2.98s/it, fold 1 mae 30.007 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Fold 1 MAE: 30.007 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training XGBoost:  40%|████      | 2/5 [00:05<00:08,  2.88s/it, fold 2 mae 29.149 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Fold 2 MAE: 29.149 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training XGBoost:  60%|██████    | 3/5 [00:08<00:05,  2.87s/it, fold 3 mae 28.807 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Fold 3 MAE: 28.807 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training XGBoost:  80%|████████  | 4/5 [00:11<00:02,  2.86s/it, fold 4 mae 29.399 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Fold 4 MAE: 29.399 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training XGBoost: 100%|██████████| 5/5 [00:14<00:00,  2.86s/it, fold 5 mae 28.837 K]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Fold 5 MAE: 28.837 K\n",
      "XGBoost - Average MAE: 29.240 +/- 0.441 K\n",
      "\n",
      "=== Evaluating: CatBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CatBoost:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3023334\ttest: 0.3079584\tbest: 0.3079584 (0)\ttotal: 48ms\tremaining: 24s\n",
      "100:\tlearn: 0.1468339\ttest: 0.1726140\tbest: 0.1726140 (100)\ttotal: 2.35s\tremaining: 9.28s\n",
      "200:\tlearn: 0.1275699\ttest: 0.1607006\tbest: 0.1607006 (200)\ttotal: 4.55s\tremaining: 6.77s\n",
      "300:\tlearn: 0.1213853\ttest: 0.1578338\tbest: 0.1578338 (300)\ttotal: 6.72s\tremaining: 4.44s\n",
      "400:\tlearn: 0.1152299\ttest: 0.1554998\tbest: 0.1554959 (399)\ttotal: 8.93s\tremaining: 2.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CatBoost:  20%|██        | 1/5 [00:11<00:46, 11.57s/it, fold 1 mae 31.034 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499:\tlearn: 0.1116463\ttest: 0.1544331\tbest: 0.1544317 (498)\ttotal: 11.1s\tremaining: 0us\n",
      "bestTest = 0.1544317437\n",
      "bestIteration = 498\n",
      "Shrink model to first 499 iterations.\n",
      "CatBoost Fold 1 MAE: 31.034 K\n",
      "0:\tlearn: 0.3028670\ttest: 0.3065518\tbest: 0.3065518 (0)\ttotal: 23.5ms\tremaining: 11.7s\n",
      "100:\tlearn: 0.1474291\ttest: 0.1648084\tbest: 0.1648084 (100)\ttotal: 2.32s\tremaining: 9.16s\n",
      "200:\tlearn: 0.1266338\ttest: 0.1527948\tbest: 0.1527948 (200)\ttotal: 4.56s\tremaining: 6.79s\n",
      "300:\tlearn: 0.1179519\ttest: 0.1490288\tbest: 0.1490288 (300)\ttotal: 6.77s\tremaining: 4.48s\n",
      "400:\tlearn: 0.1118001\ttest: 0.1470492\tbest: 0.1470390 (399)\ttotal: 8.97s\tremaining: 2.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CatBoost:  40%|████      | 2/5 [00:22<00:34, 11.47s/it, fold 2 mae 29.778 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499:\tlearn: 0.1082566\ttest: 0.1460604\tbest: 0.1460422 (495)\ttotal: 11.1s\tremaining: 0us\n",
      "bestTest = 0.1460422453\n",
      "bestIteration = 495\n",
      "Shrink model to first 496 iterations.\n",
      "CatBoost Fold 2 MAE: 29.778 K\n",
      "0:\tlearn: 0.3035551\ttest: 0.3034214\tbest: 0.3034214 (0)\ttotal: 23.3ms\tremaining: 11.6s\n",
      "100:\tlearn: 0.1468892\ttest: 0.1688843\tbest: 0.1688843 (100)\ttotal: 2.33s\tremaining: 9.19s\n",
      "200:\tlearn: 0.1267725\ttest: 0.1598783\tbest: 0.1598783 (200)\ttotal: 4.56s\tremaining: 6.78s\n",
      "300:\tlearn: 0.1185225\ttest: 0.1579531\tbest: 0.1579043 (290)\ttotal: 6.75s\tremaining: 4.46s\n",
      "400:\tlearn: 0.1122379\ttest: 0.1566049\tbest: 0.1565990 (399)\ttotal: 8.94s\tremaining: 2.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CatBoost:  60%|██████    | 3/5 [00:34<00:22, 11.43s/it, fold 3 mae 29.950 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499:\tlearn: 0.1080775\ttest: 0.1559940\tbest: 0.1559888 (497)\ttotal: 11.1s\tremaining: 0us\n",
      "bestTest = 0.1559887588\n",
      "bestIteration = 497\n",
      "Shrink model to first 498 iterations.\n",
      "CatBoost Fold 3 MAE: 29.950 K\n",
      "0:\tlearn: 0.3026603\ttest: 0.3066872\tbest: 0.3066872 (0)\ttotal: 24ms\tremaining: 12s\n",
      "100:\tlearn: 0.1494117\ttest: 0.1673973\tbest: 0.1673973 (100)\ttotal: 2.31s\tremaining: 9.14s\n",
      "200:\tlearn: 0.1307333\ttest: 0.1533625\tbest: 0.1533625 (200)\ttotal: 4.53s\tremaining: 6.74s\n",
      "300:\tlearn: 0.1223821\ttest: 0.1485985\tbest: 0.1485985 (300)\ttotal: 6.69s\tremaining: 4.42s\n",
      "400:\tlearn: 0.1178869\ttest: 0.1462069\tbest: 0.1462069 (400)\ttotal: 8.89s\tremaining: 2.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CatBoost:  80%|████████  | 4/5 [00:45<00:11, 11.40s/it, fold 4 mae 30.622 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499:\tlearn: 0.1143064\ttest: 0.1443914\tbest: 0.1443914 (499)\ttotal: 11.1s\tremaining: 0us\n",
      "bestTest = 0.1443914192\n",
      "bestIteration = 499\n",
      "CatBoost Fold 4 MAE: 30.622 K\n",
      "0:\tlearn: 0.3058040\ttest: 0.2943333\tbest: 0.2943333 (0)\ttotal: 24.2ms\tremaining: 12.1s\n",
      "100:\tlearn: 0.1480444\ttest: 0.1676858\tbest: 0.1676858 (100)\ttotal: 2.31s\tremaining: 9.12s\n",
      "200:\tlearn: 0.1279824\ttest: 0.1554998\tbest: 0.1554998 (200)\ttotal: 4.51s\tremaining: 6.71s\n",
      "300:\tlearn: 0.1183413\ttest: 0.1504963\tbest: 0.1504963 (300)\ttotal: 6.72s\tremaining: 4.44s\n",
      "400:\tlearn: 0.1119353\ttest: 0.1473385\tbest: 0.1473385 (400)\ttotal: 8.91s\tremaining: 2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CatBoost: 100%|██████████| 5/5 [00:57<00:00, 11.42s/it, fold 5 mae 29.259 K]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499:\tlearn: 0.1070211\ttest: 0.1454555\tbest: 0.1454555 (499)\ttotal: 11.1s\tremaining: 0us\n",
      "bestTest = 0.1454555242\n",
      "bestIteration = 499\n",
      "CatBoost Fold 5 MAE: 29.259 K\n",
      "CatBoost - Average MAE: 30.129 +/- 0.629 K\n",
      "\n",
      "=== Evaluating: KNN ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training KNN:  40%|████      | 2/5 [00:00<00:00, 17.34it/s, fold 2 mae 38.134 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Fold 1 MAE: 38.184 K\n",
      "KNN Fold 2 MAE: 38.134 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training KNN: 100%|██████████| 5/5 [00:00<00:00, 24.93it/s, fold 5 mae 40.062 K]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Fold 3 MAE: 36.023 K\n",
      "KNN Fold 4 MAE: 36.780 K\n",
      "KNN Fold 5 MAE: 40.062 K\n",
      "KNN - Average MAE: 37.837 +/- 1.383 K\n",
      "\n",
      "Final results summary:\n",
      "Ridge: mean MAE = 34.565 K, std = 1.586 K\n",
      "ElasticNet: mean MAE = 47.138 K, std = 1.806 K\n",
      "RandomForest: mean MAE = 30.995 K, std = 0.707 K\n",
      "HistGB: mean MAE = 28.275 K, std = 0.399 K\n",
      "LightGBM: mean MAE = 28.187 K, std = 0.524 K\n",
      "XGBoost: mean MAE = 29.240 K, std = 0.441 K\n",
      "CatBoost: mean MAE = 30.129 K, std = 0.629 K\n",
      "KNN: mean MAE = 37.837 K, std = 1.383 K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model, scale, extra_params in models:\n",
    "    print(f\"=== Evaluating: {name} ===\")\n",
    "    try:\n",
    "        if name == 'LightGBM':\n",
    "            evaluate_model_cv(name, model, scale=scale, lgb_params=extra_params)\n",
    "        elif name == 'XGBoost':\n",
    "            evaluate_model_cv(name, model, scale=scale, xgb_params=extra_params)\n",
    "        elif name == 'CatBoost':\n",
    "            evaluate_model_cv(name, model, scale=scale, cat_params=extra_params)\n",
    "        else:\n",
    "            evaluate_model_cv(name, model, scale=scale)\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {name} failed: {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"Final results summary:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: mean MAE = {v['mean_mae']:.3f} K, std = {v['std_mae']:.3f} K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7103404e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble Top 3:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[390]\tvalid_0's l2: 0.0222472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble Top 3:  20%|██        | 1/5 [00:07<00:29,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Fold 1 MAE: 28.503 K\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[396]\tvalid_0's l2: 0.0189527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble Top 3:  40%|████      | 2/5 [00:14<00:22,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Fold 2 MAE: 27.611 K\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\tvalid_0's l2: 0.0217702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble Top 3:  60%|██████    | 3/5 [00:22<00:14,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Fold 3 MAE: 27.387 K\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\tvalid_0's l2: 0.018964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble Top 3:  80%|████████  | 4/5 [00:29<00:07,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Fold 4 MAE: 28.434 K\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\tvalid_0's l2: 0.0187805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble Top 3: 100%|██████████| 5/5 [00:37<00:00,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Fold 5 MAE: 27.638 K\n",
      "Ensemble - Average MAE: 27.915 +/- 0.461 K\n",
      "\n",
      "=== Final Results with Ensemble ===\n",
      "Ridge: mean MAE = 34.56499, std = 1.58619\n",
      "ElasticNet: mean MAE = 47.13790, std = 1.80632\n",
      "RandomForest: mean MAE = 30.99477, std = 0.70658\n",
      "HistGB: mean MAE = 28.27533, std = 0.39901\n",
      "LightGBM: mean MAE = 28.18726, std = 0.52371\n",
      "XGBoost: mean MAE = 29.23981, std = 0.44053\n",
      "CatBoost: mean MAE = 30.12858, std = 0.62853\n",
      "KNN: mean MAE = 37.83654, std = 1.38321\n",
      "EnsembleTop3: mean MAE = 27.91452, std = 0.46087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "from xgboost import callback\n",
    "def ensemble_top3(models, X, y, kf):\n",
    "    oof_preds = np.zeros(len(y))\n",
    "    mae_list = []\n",
    "\n",
    "    it = tqdm(kf.split(X, y), total=kf.get_n_splits(), desc=\"Ensemble Top 3\", leave=True)\n",
    "    for fold_idx, (tr_idx, val_idx) in enumerate(it):\n",
    "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "\n",
    "        fold_preds = []\n",
    "        for name, model, params in models:\n",
    "            m = clone(model)\n",
    "            \n",
    "            if name == 'LightGBM':\n",
    "                m.set_params(**params)\n",
    "                m.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    callbacks=[\n",
    "                        lgb.early_stopping(stopping_rounds=50),\n",
    "                        lgb.log_evaluation(0)\n",
    "                    ]\n",
    "                )\n",
    "                fold_preds.append(m.predict(X_val, num_iteration=m.best_iteration_))\n",
    "            \n",
    "            elif name == 'XGBoost':\n",
    "                m.set_params(**params)\n",
    "                m.fit(X_tr, y_tr)\n",
    "                fold_preds.append(m.predict(X_val))\n",
    "            \n",
    "            else:  # HistGradientBoosting\n",
    "                m.fit(X_tr, y_tr)\n",
    "                fold_preds.append(m.predict(X_val))\n",
    "\n",
    "        y_pred = np.mean(fold_preds, axis=0)\n",
    "        oof_preds[val_idx] = y_pred\n",
    "\n",
    "        mae = mean_absolute_error(np.exp(y_val), np.exp(y_pred))\n",
    "        mae_list.append(mae)\n",
    "        print(f\"Ensemble Fold {fold_idx+1} MAE: {mae:.3f} K\")\n",
    "\n",
    "    mean_mae = np.mean(mae_list)\n",
    "    std_mae = np.std(mae_list)\n",
    "    print(f\"Ensemble - Average MAE: {mean_mae:.3f} +/- {std_mae:.3f} K\")\n",
    "    return oof_preds, mean_mae, std_mae\n",
    "\n",
    "\n",
    "top3_models = [\n",
    "    ('LightGBM', lgb.LGBMRegressor(**LGB_PARAMS), LGB_PARAMS),\n",
    "    ('HistGB', HistGradientBoostingRegressor(max_iter=300, max_depth=10, random_state=RANDOM_STATE), {}),\n",
    "    ('XGBoost', xgb.XGBRegressor(**XGB_PARAMS), XGB_PARAMS),\n",
    "]\n",
    "\n",
    "ensemble_oof, ens_mean, ens_std = ensemble_top3(top3_models, X, y, kf)\n",
    "\n",
    "results['EnsembleTop3'] = {'mean_mae': ens_mean, 'std_mae': ens_std}\n",
    "\n",
    "print(\"\\n=== Final Results with Ensemble ===\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: mean MAE = {v['mean_mae']:.5f}, std = {v['std_mae']:.5f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd08062d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Importances (LightGBM) ===\n",
      "              feature  importance\n",
      "163         PEOE_VSA7         261\n",
      "121  FpDensityMorgan2         259\n",
      "132          BalabanJ         244\n",
      "117  MinPartialCharge         243\n",
      "205       VSA_EState8         240\n",
      "129       BCUT2D_MRHI         234\n",
      "122  FpDensityMorgan3         231\n",
      "127     BCUT2D_LOGPHI         221\n",
      "128    BCUT2D_LOGPLOW         215\n",
      "186              TPSA         214\n",
      "133           BertzCT         209\n",
      "130      BCUT2D_MRLOW         206\n",
      "120  FpDensityMorgan1         203\n",
      "204       VSA_EState7         176\n",
      "150            Kappa3         176\n",
      "\n",
      "=== Feature Importances (XGBoost) ===\n",
      "                    feature  importance\n",
      "133                 BertzCT    0.120085\n",
      "209               NHOHCount    0.106629\n",
      "230               RingCount    0.055161\n",
      "113              ExactMolWt    0.042661\n",
      "221              NumHDonors    0.040694\n",
      "186                    TPSA    0.040424\n",
      "112          HeavyAtomMolWt    0.028706\n",
      "210                 NOCount    0.021037\n",
      "55                Group_170    0.020086\n",
      "291  fr_phenol_noOrthoHbond    0.015299\n",
      "197             VSA_EState1    0.013727\n",
      "217        NumAromaticRings    0.013297\n",
      "95                Group_373    0.012516\n",
      "151               LabuteASA    0.010882\n",
      "147                     Ipc    0.010518\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance\n",
    "print(\"\\n=== Feature Importances (LightGBM) ===\")\n",
    "lgb_model = lgb.LGBMRegressor(**LGB_PARAMS)\n",
    "lgb_model.fit(X, y)\n",
    "lgb_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': lgb_model.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "print(lgb_importance.head(15))\n",
    "\n",
    "print(\"\\n=== Feature Importances (XGBoost) ===\")\n",
    "xgb_model = xgb.XGBRegressor(**XGB_PARAMS)\n",
    "xgb_model.fit(X, y)\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "print(xgb_importance.head(15))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
