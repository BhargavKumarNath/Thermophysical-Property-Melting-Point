{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d758fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b0f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_torch_cuda():\n",
    "    try:\n",
    "        import torch\n",
    "        return torch.cuda.is_available()\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def get_nvidia_gpu_free_memory_mb():\n",
    "    try:\n",
    "        import pynvml\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "        info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        free_mb = info.free // (1024 * 1024)\n",
    "        total_mb = info.total // (1024 * 1024)\n",
    "        pynvml.nvmlShutdown()\n",
    "        return free_mb, total_mb\n",
    "    except Exception:\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8ac318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Project\\Thermophysical Property Melting Point\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU] Free memory detected: 7776 MB / 8188 MB\n",
      "CATBOOST_USE_GPU=True, LIGHTGBM_GPU=True, XGBOOST_GPU=True\n"
     ]
    }
   ],
   "source": [
    "GPU_AVAILABLE = has_torch_cuda()\n",
    "FREE_GPU_MB, TOTAL_GPU_MB = get_nvidia_gpu_free_memory_mb()\n",
    "if FREE_GPU_MB is not None:\n",
    "    print(f\"[GPU] Free memory detected: {FREE_GPU_MB} MB / {TOTAL_GPU_MB} MB\")\n",
    "else:\n",
    "    print(f\"[GPU] Could not detect GPU memory via pynvml. Torch reports CUDA available: {GPU_AVAILABLE}\")\n",
    "\n",
    "CATBOOST_GPU_MIN_MB = 6000  \n",
    "CATBOOST_USE_GPU = False\n",
    "if GPU_AVAILABLE and FREE_GPU_MB is not None and FREE_GPU_MB >= CATBOOST_GPU_MIN_MB:\n",
    "    CATBOOST_USE_GPU = True\n",
    "elif GPU_AVAILABLE and FREE_GPU_MB is None:\n",
    "    CATBOOST_USE_GPU = True\n",
    "\n",
    "USE_GPU_FOR_LIGHTGBM = GPU_AVAILABLE\n",
    "USE_GPU_FOR_XGBOOST = GPU_AVAILABLE\n",
    "\n",
    "print(f\"CATBOOST_USE_GPU={CATBOOST_USE_GPU}, LIGHTGBM_GPU={USE_GPU_FOR_LIGHTGBM}, XGBOOST_GPU={USE_GPU_FOR_XGBOOST}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a780c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_SPLITS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Keep features manageable\n",
    "TOP_K_FEATURES = 2000\n",
    "\n",
    "LGB_PARAMS = {\n",
    "    'n_estimators': 400,\n",
    "    'learning_rate': 0.03,\n",
    "    'max_depth': 10,\n",
    "    'n_jobs': -1,\n",
    "    'verbose': -1,\n",
    "    'device_type': 'gpu' if USE_GPU_FOR_LIGHTGBM else 'cpu',\n",
    "}\n",
    "\n",
    "XGB_PARAMS = {\n",
    "    'n_estimators': 400,\n",
    "    'learning_rate': 0.03,\n",
    "    'max_depth': 8,\n",
    "    'tree_method': 'hist',\n",
    "    'verbosity': 0,\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'n_jobs': -1,\n",
    "    'device': 'cuda' if USE_GPU_FOR_XGBOOST else 'cpu'\n",
    "}\n",
    "\n",
    "CAT_PARAMS = {\n",
    "    'iterations': 500,\n",
    "    'learning_rate': 0.03,\n",
    "    'depth': 8,\n",
    "    'verbose': 100,\n",
    "    'random_state': RANDOM_STATE,\n",
    "}\n",
    "\n",
    "if not CATBOOST_USE_GPU:\n",
    "    CAT_PARAMS['iterations'] = 250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6880c853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train/test\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/processed/train_processed.csv')\n",
    "test_df = pd.read_csv('../data/processed/test_processed.csv')\n",
    "\n",
    "print(\"Loaded train/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b135990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial numeric feature count: 322\n"
     ]
    }
   ],
   "source": [
    "features = [c for c in test_df.columns if c not in ['id', 'SMILES']]\n",
    "X = train_df[features].copy()\n",
    "y = train_df['Tm'].copy()\n",
    "\n",
    "X = X.copy()\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n",
    "\n",
    "X.columns = [c.strip().replace(' ', '_') for c in X.columns]\n",
    "\n",
    "print(f\"Initial numeric feature count: {X.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdca613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After variance thresholding: 307 features remain\n",
      "Using 307 features for modeling\n"
     ]
    }
   ],
   "source": [
    "vt = VarianceThreshold(threshold=1e-8)\n",
    "try:\n",
    "    X = pd.DataFrame(vt.fit_transform(X), columns=[c for i,c in enumerate(X.columns) if vt.get_support()[i]])\n",
    "    print(f\"After variance thresholding: {X.shape[1]} features remain\")\n",
    "except Exception:\n",
    "    X = X.select_dtypes(include=[np.number])\n",
    "    print(f\"After forcing numeric selection: {X.shape[1]} features remain\")\n",
    "\n",
    "def select_top_k_by_corr(X_df, y_series, k=TOP_K_FEATURES):\n",
    "    numeric = X_df.select_dtypes(include=[np.number]).columns\n",
    "    cors = {}\n",
    "    for c in numeric:\n",
    "        col = X_df[c].values\n",
    "        if np.nanstd(col) == 0:\n",
    "            continue\n",
    "        corr = np.corrcoef(col, y_series.values)[0,1]\n",
    "        if np.isfinite(corr):\n",
    "            cors[c] = abs(corr)\n",
    "    if not cors:\n",
    "        return X_df\n",
    "    sel = sorted(cors.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "    cols = [c for c, _ in sel]\n",
    "    return X_df[cols]\n",
    "\n",
    "if X.shape[1] > TOP_K_FEATURES:\n",
    "    X = select_top_k_by_corr(X, y, k=TOP_K_FEATURES)\n",
    "    print(f\"Selected top {X.shape[1]} features by correlation\")\n",
    "\n",
    "print(f\"Using {X.shape[1]} features for modeling\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe64b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET: all positive -> log-transform ENABLED\n"
     ]
    }
   ],
   "source": [
    "# Reset indices for safe iloc slicing\n",
    "X = X.reset_index(drop=True)\n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "USE_LOG_TARGET = False\n",
    "if (y > 0).all():\n",
    "    USE_LOG_TARGET = True\n",
    "    print(\"TARGET: all positive -> log-transform ENABLED\")\n",
    "else:\n",
    "    print(\"TARGET: contains non-positive values -> log-transform DISABLED (to avoid -inf/nan)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057ce7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "results = {}\n",
    "\n",
    "def evaluate_model_cv(name, model, scale=False, use_log=USE_LOG_TARGET, lgb_params=None, xgb_params=None, cat_params=None):\n",
    "    mae_list = []\n",
    "    steps = []\n",
    "    if scale:\n",
    "        steps.append(('scaler', StandardScaler()))\n",
    "    steps.append(('model', model))\n",
    "    pipe = Pipeline(steps)\n",
    "    \n",
    "    it = tqdm(kf.split(X, y), total=kf.get_n_splits(), desc=f'Training {name}', leave=True)\n",
    "    for fold_idx, (tr_idx, val_idx) in enumerate(it):\n",
    "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "\n",
    "        if use_log:\n",
    "            y_tr_fit = np.log(y_tr)\n",
    "            pipe.fit(X_tr, y_tr_fit)\n",
    "            y_pred_log = pipe.predict(X_val)\n",
    "            y_pred = np.exp(y_pred_log)\n",
    "        else:\n",
    "            if name == 'LightGBM' and isinstance(model, lgb.LGBMRegressor):\n",
    "                model.set_params(**(lgb_params or {}))\n",
    "                model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], early_stopping_rounds=50, verbose=False)\n",
    "                y_pred = model.predict(X_val, num_iteration=model.best_iteration_)\n",
    "            elif name == 'XGBoost' and isinstance(model, xgb.XGBRegressor):\n",
    "                model.set_params(**(xgb_params or {}))\n",
    "                model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], early_stopping_rounds=50, verbose=False)\n",
    "                y_pred = model.predict(X_val)\n",
    "            elif name == 'CatBoost' and isinstance(model, CatBoostRegressor):\n",
    "                model.set_params(**(cat_params or {}))\n",
    "                model.fit(X_tr, y_tr, eval_set=(X_val, y_val), use_best_model=True, verbose=cat_params.get('verbose', False))\n",
    "                y_pred = model.predict(X_val)\n",
    "            else:\n",
    "                pipe.fit(X_tr, y_tr)\n",
    "                y_pred = pipe.predict(X_val)\n",
    "\n",
    "        if np.any(np.isnan(y_pred)):\n",
    "            y_pred = np.nan_to_num(y_pred, nan=np.nanmedian(y_pred))\n",
    "        mae = mean_absolute_error(y_val.values, y_pred)\n",
    "        mae_list.append(mae)\n",
    "        it.set_postfix_str(f\"fold {fold_idx+1} mae {mae:.5f}\")\n",
    "        print(f\"{name} Fold {fold_idx+1} MAE: {mae:.5f}\")\n",
    "\n",
    "    mean_mae = np.mean(mae_list)\n",
    "    std_mae = np.std(mae_list)\n",
    "    results[name] = {'mean_mae': mean_mae, 'std_mae': std_mae}\n",
    "    print(f\"{name} - Average MAE: {mean_mae:.5f} +/- {std_mae:.5f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27648d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('Ridge', Ridge(alpha=1.0, random_state=RANDOM_STATE), True, {}),\n",
    "    ('ElasticNet', ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=RANDOM_STATE), True, {}),\n",
    "    ('RandomForest', RandomForestRegressor(n_estimators=200, max_depth=12, random_state=RANDOM_STATE, n_jobs=-1), False, {}),\n",
    "    ('HistGB', HistGradientBoostingRegressor(max_iter=300, max_depth=10, random_state=RANDOM_STATE), False, {}),\n",
    "\n",
    "    ('LightGBM', lgb.LGBMRegressor(**LGB_PARAMS), False, LGB_PARAMS),\n",
    "\n",
    "    ('XGBoost', xgb.XGBRegressor(**XGB_PARAMS), False, XGB_PARAMS),\n",
    "\n",
    "    ('CatBoost', CatBoostRegressor(task_type='GPU' if CATBOOST_USE_GPU else 'CPU', devices='0' if CATBOOST_USE_GPU else None,\n",
    "                                  iterations=CAT_PARAMS['iterations'],\n",
    "                                  learning_rate=CAT_PARAMS['learning_rate'],\n",
    "                                  depth=CAT_PARAMS['depth'],\n",
    "                                  random_seed=RANDOM_STATE,\n",
    "                                  verbose=CAT_PARAMS.get('verbose', 100),\n",
    "                                  allow_writing_files=False),\n",
    "     False, CAT_PARAMS),\n",
    "\n",
    "    ('KNN', KNeighborsRegressor(n_neighbors=5, n_jobs=-1), True, {}),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a5366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluating: Ridge ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Ridge:   0%|          | 0/5 [00:00<?, ?it/s, fold 3 mae 0.11809]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Fold 1 MAE: 0.12490\n",
      "Ridge Fold 2 MAE: 0.11782\n",
      "Ridge Fold 3 MAE: 0.11809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Ridge: 100%|██████████| 5/5 [00:00<00:00, 46.58it/s, fold 5 mae 0.13041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Fold 4 MAE: 0.12626\n",
      "Ridge Fold 5 MAE: 0.13041\n",
      "Ridge - Average MAE: 0.12349 +/- 0.00487\n",
      "\n",
      "=== Evaluating: ElasticNet ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training ElasticNet:   0%|          | 0/5 [00:00<?, ?it/s, fold 1 mae 0.24677]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet Fold 1 MAE: 0.24677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training ElasticNet:   0%|          | 0/5 [00:00<?, ?it/s, fold 3 mae 0.24954]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet Fold 2 MAE: 0.24221\n",
      "ElasticNet Fold 3 MAE: 0.24954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training ElasticNet: 100%|██████████| 5/5 [00:00<00:00, 63.47it/s, fold 5 mae 0.23988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet Fold 4 MAE: 0.24671\n",
      "ElasticNet Fold 5 MAE: 0.23988\n",
      "ElasticNet - Average MAE: 0.24502 +/- 0.00348\n",
      "\n",
      "=== Evaluating: RandomForest ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training RandomForest:  20%|██        | 1/5 [00:01<00:05,  1.30s/it, fold 1 mae 0.11223]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Fold 1 MAE: 0.11223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training RandomForest:  40%|████      | 2/5 [00:02<00:03,  1.31s/it, fold 2 mae 0.11017]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Fold 2 MAE: 0.11017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training RandomForest:  60%|██████    | 3/5 [00:04<00:02,  1.38s/it, fold 3 mae 0.11057]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Fold 3 MAE: 0.11057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training RandomForest:  80%|████████  | 4/5 [00:05<00:01,  1.37s/it, fold 4 mae 0.11464]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Fold 4 MAE: 0.11464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training RandomForest: 100%|██████████| 5/5 [00:06<00:00,  1.35s/it, fold 5 mae 0.10780]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Fold 5 MAE: 0.10780\n",
      "RandomForest - Average MAE: 0.11108 +/- 0.00227\n",
      "\n",
      "=== Evaluating: HistGB ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training HistGB:  20%|██        | 1/5 [00:03<00:14,  3.66s/it, fold 1 mae 0.10391]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGB Fold 1 MAE: 0.10391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training HistGB:  40%|████      | 2/5 [00:06<00:08,  2.97s/it, fold 2 mae 0.09870]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGB Fold 2 MAE: 0.09870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training HistGB:  60%|██████    | 3/5 [00:08<00:05,  2.72s/it, fold 3 mae 0.10059]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGB Fold 3 MAE: 0.10059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training HistGB:  80%|████████  | 4/5 [00:10<00:02,  2.57s/it, fold 4 mae 0.10470]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGB Fold 4 MAE: 0.10470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training HistGB: 100%|██████████| 5/5 [00:13<00:00,  2.66s/it, fold 5 mae 0.09869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGB Fold 5 MAE: 0.09869\n",
      "HistGB - Average MAE: 0.10132 +/- 0.00255\n",
      "\n",
      "=== Evaluating: LightGBM ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM:  20%|██        | 1/5 [00:05<00:23,  5.97s/it, fold 1 mae 0.10301]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Fold 1 MAE: 0.10301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM:  40%|████      | 2/5 [00:08<00:11,  3.97s/it, fold 2 mae 0.10060]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Fold 2 MAE: 0.10060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM:  60%|██████    | 3/5 [00:10<00:06,  3.24s/it, fold 3 mae 0.10047]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Fold 3 MAE: 0.10047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM:  80%|████████  | 4/5 [00:13<00:02,  2.86s/it, fold 4 mae 0.10397]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Fold 4 MAE: 0.10397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LightGBM: 100%|██████████| 5/5 [00:15<00:00,  3.11s/it, fold 5 mae 0.09621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Fold 5 MAE: 0.09621\n",
      "LightGBM - Average MAE: 0.10085 +/- 0.00269\n",
      "\n",
      "=== Evaluating: XGBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training XGBoost:  20%|██        | 1/5 [00:02<00:11,  2.99s/it, fold 1 mae 0.10913]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Fold 1 MAE: 0.10913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training XGBoost:  40%|████      | 2/5 [00:05<00:08,  2.87s/it, fold 2 mae 0.10410]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Fold 2 MAE: 0.10410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training XGBoost:  60%|██████    | 3/5 [00:08<00:05,  2.86s/it, fold 3 mae 0.10467]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Fold 3 MAE: 0.10467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training XGBoost:  80%|████████  | 4/5 [00:11<00:02,  2.84s/it, fold 4 mae 0.10699]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Fold 4 MAE: 0.10699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training XGBoost: 100%|██████████| 5/5 [00:14<00:00,  2.84s/it, fold 5 mae 0.09960]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Fold 5 MAE: 0.09960\n",
      "XGBoost - Average MAE: 0.10490 +/- 0.00319\n",
      "\n",
      "=== Evaluating: CatBoost ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CatBoost:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.0548703\ttotal: 120ms\tremaining: 59.7s\n",
      "100:\tlearn: 0.0263770\ttotal: 2.38s\tremaining: 9.41s\n",
      "200:\tlearn: 0.0228651\ttotal: 4.58s\tremaining: 6.81s\n",
      "300:\tlearn: 0.0216748\ttotal: 6.74s\tremaining: 4.45s\n",
      "400:\tlearn: 0.0206742\ttotal: 8.9s\tremaining: 2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CatBoost:  20%|██        | 1/5 [00:11<00:46, 11.52s/it, fold 1 mae 0.11081]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499:\tlearn: 0.0200660\ttotal: 11s\tremaining: 0us\n",
      "CatBoost Fold 1 MAE: 0.11081\n",
      "0:\tlearn: 0.0549402\ttotal: 22.8ms\tremaining: 11.4s\n",
      "100:\tlearn: 0.0265992\ttotal: 2.27s\tremaining: 8.98s\n",
      "200:\tlearn: 0.0227784\ttotal: 4.45s\tremaining: 6.62s\n",
      "300:\tlearn: 0.0211853\ttotal: 6.61s\tremaining: 4.37s\n",
      "400:\tlearn: 0.0201536\ttotal: 8.77s\tremaining: 2.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CatBoost:  40%|████      | 2/5 [00:22<00:33, 11.31s/it, fold 2 mae 0.10754]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499:\tlearn: 0.0194226\ttotal: 10.9s\tremaining: 0us\n",
      "CatBoost Fold 2 MAE: 0.10754\n",
      "0:\tlearn: 0.0549899\ttotal: 23.3ms\tremaining: 11.6s\n",
      "100:\tlearn: 0.0265745\ttotal: 2.3s\tremaining: 9.1s\n",
      "200:\tlearn: 0.0228932\ttotal: 4.5s\tremaining: 6.7s\n",
      "300:\tlearn: 0.0213469\ttotal: 6.67s\tremaining: 4.41s\n",
      "400:\tlearn: 0.0202327\ttotal: 8.82s\tremaining: 2.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CatBoost:  60%|██████    | 3/5 [00:33<00:22, 11.25s/it, fold 3 mae 0.10816]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499:\tlearn: 0.0195059\ttotal: 10.9s\tremaining: 0us\n",
      "CatBoost Fold 3 MAE: 0.10816\n",
      "0:\tlearn: 0.0549488\ttotal: 22.4ms\tremaining: 11.2s\n",
      "100:\tlearn: 0.0269808\ttotal: 2.25s\tremaining: 8.88s\n",
      "200:\tlearn: 0.0234270\ttotal: 4.42s\tremaining: 6.58s\n",
      "300:\tlearn: 0.0221162\ttotal: 6.57s\tremaining: 4.34s\n",
      "400:\tlearn: 0.0210502\ttotal: 8.71s\tremaining: 2.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CatBoost:  80%|████████  | 4/5 [00:44<00:11, 11.18s/it, fold 4 mae 0.10951]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499:\tlearn: 0.0203029\ttotal: 10.8s\tremaining: 0us\n",
      "CatBoost Fold 4 MAE: 0.10951\n",
      "0:\tlearn: 0.0555841\ttotal: 23.8ms\tremaining: 11.9s\n",
      "100:\tlearn: 0.0268140\ttotal: 2.3s\tremaining: 9.09s\n",
      "200:\tlearn: 0.0229414\ttotal: 4.48s\tremaining: 6.66s\n",
      "300:\tlearn: 0.0211402\ttotal: 6.65s\tremaining: 4.4s\n",
      "400:\tlearn: 0.0198930\ttotal: 8.81s\tremaining: 2.17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training CatBoost: 100%|██████████| 5/5 [00:56<00:00, 11.23s/it, fold 5 mae 0.10294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499:\tlearn: 0.0190845\ttotal: 10.9s\tremaining: 0us\n",
      "CatBoost Fold 5 MAE: 0.10294\n",
      "CatBoost - Average MAE: 0.10779 +/- 0.00268\n",
      "\n",
      "=== Evaluating: KNN ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training KNN:  40%|████      | 2/5 [00:00<00:00, 16.95it/s, fold 2 mae 0.14316]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Fold 1 MAE: 0.13920\n",
      "KNN Fold 2 MAE: 0.14316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training KNN: 100%|██████████| 5/5 [00:00<00:00, 23.98it/s, fold 5 mae 0.14622]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Fold 3 MAE: 0.13404\n",
      "KNN Fold 4 MAE: 0.13499\n",
      "KNN Fold 5 MAE: 0.14622\n",
      "KNN - Average MAE: 0.13952 +/- 0.00467\n",
      "\n",
      "Final results summary:\n",
      "Ridge: mean MAE = 0.12349, std = 0.00487\n",
      "ElasticNet: mean MAE = 0.24502, std = 0.00348\n",
      "RandomForest: mean MAE = 0.11108, std = 0.00227\n",
      "HistGB: mean MAE = 0.10132, std = 0.00255\n",
      "LightGBM: mean MAE = 0.10085, std = 0.00269\n",
      "XGBoost: mean MAE = 0.10490, std = 0.00319\n",
      "CatBoost: mean MAE = 0.10779, std = 0.00268\n",
      "KNN: mean MAE = 0.13952, std = 0.00467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model, scale, extra_params in models:\n",
    "    print(f\"=== Evaluating: {name} ===\")\n",
    "    try:\n",
    "        if name == 'LightGBM':\n",
    "            evaluate_model_cv(name, model, scale=scale, use_log=USE_LOG_TARGET, lgb_params=extra_params)\n",
    "        elif name == 'XGBoost':\n",
    "            evaluate_model_cv(name, model, scale=scale, use_log=USE_LOG_TARGET, xgb_params=extra_params)\n",
    "        elif name == 'CatBoost':\n",
    "            evaluate_model_cv(name, model, scale=scale, use_log=USE_LOG_TARGET, cat_params=extra_params)\n",
    "        else:\n",
    "            evaluate_model_cv(name, model, scale=scale, use_log=USE_LOG_TARGET)\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {name} failed: {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"Final results summary:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: mean MAE = {v['mean_mae']:.5f}, std = {v['std_mae']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7103404e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a8bab3051540d2b95d2f76d4b92136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ensemble Top 3:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[390]\tvalid_0's l2: 0.0222541\n",
      "Ensemble Fold 1 MAE: 0.10209\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[396]\tvalid_0's l2: 0.0189421\n",
      "Ensemble Fold 2 MAE: 0.09902\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\tvalid_0's l2: 0.0217741\n",
      "Ensemble Fold 3 MAE: 0.09920\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\tvalid_0's l2: 0.0189577\n",
      "Ensemble Fold 4 MAE: 0.10172\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[399]\tvalid_0's l2: 0.0187803\n",
      "Ensemble Fold 5 MAE: 0.09687\n",
      "Ensemble - Average MAE: 0.09978 +/- 0.00192\n",
      "\n",
      "=== Final Results with Ensemble ===\n",
      "Ridge: mean MAE = 0.12349, std = 0.00487\n",
      "ElasticNet: mean MAE = 0.24502, std = 0.00348\n",
      "RandomForest: mean MAE = 0.11108, std = 0.00227\n",
      "HistGB: mean MAE = 0.10132, std = 0.00255\n",
      "LightGBM: mean MAE = 0.10085, std = 0.00269\n",
      "XGBoost: mean MAE = 0.10490, std = 0.00319\n",
      "CatBoost: mean MAE = 0.10779, std = 0.00268\n",
      "KNN: mean MAE = 0.13952, std = 0.00467\n",
      "EnsembleTop3: mean MAE = 0.09978, std = 0.00192\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "from xgboost import callback\n",
    "def ensemble_top3(models, X, y, kf):\n",
    "    oof_preds = np.zeros(len(y))\n",
    "    mae_list = []\n",
    "\n",
    "    it = tqdm(kf.split(X, y), total=kf.get_n_splits(), desc=\"Ensemble Top 3\", leave=True)\n",
    "    for fold_idx, (tr_idx, val_idx) in enumerate(it):\n",
    "        X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "\n",
    "        fold_preds = []\n",
    "        for name, model, params in models:\n",
    "            m = clone(model)\n",
    "            \n",
    "            if name == 'LightGBM':\n",
    "                m.set_params(**params)\n",
    "                m.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    callbacks=[\n",
    "                        lgb.early_stopping(stopping_rounds=50),\n",
    "                        lgb.log_evaluation(0)\n",
    "                    ]\n",
    "                )\n",
    "                fold_preds.append(m.predict(X_val, num_iteration=m.best_iteration_))\n",
    "            \n",
    "            elif name == 'XGBoost':\n",
    "                m.set_params(**params)\n",
    "                m.fit(X_tr, y_tr)\n",
    "                fold_preds.append(m.predict(X_val))\n",
    "            \n",
    "            else:  # HistGradientBoosting\n",
    "                m.fit(X_tr, y_tr)\n",
    "                fold_preds.append(m.predict(X_val))\n",
    "\n",
    "        y_pred = np.mean(fold_preds, axis=0)\n",
    "        oof_preds[val_idx] = y_pred\n",
    "\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mae_list.append(mae)\n",
    "        print(f\"Ensemble Fold {fold_idx+1} MAE: {mae:.5f}\")\n",
    "\n",
    "    mean_mae = np.mean(mae_list)\n",
    "    std_mae = np.std(mae_list)\n",
    "    print(f\"Ensemble - Average MAE: {mean_mae:.5f} +/- {std_mae:.5f}\")\n",
    "    return oof_preds, mean_mae, std_mae\n",
    "\n",
    "\n",
    "top3_models = [\n",
    "    ('LightGBM', lgb.LGBMRegressor(**LGB_PARAMS), LGB_PARAMS),\n",
    "    ('HistGB', HistGradientBoostingRegressor(max_iter=300, max_depth=10, random_state=RANDOM_STATE), {}),\n",
    "    ('XGBoost', xgb.XGBRegressor(**XGB_PARAMS), XGB_PARAMS),\n",
    "]\n",
    "\n",
    "ensemble_oof, ens_mean, ens_std = ensemble_top3(top3_models, X, y, kf)\n",
    "\n",
    "results['EnsembleTop3'] = {'mean_mae': ens_mean, 'std_mae': ens_std}\n",
    "\n",
    "print(\"\\n=== Final Results with Ensemble ===\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: mean MAE = {v['mean_mae']:.5f}, std = {v['std_mae']:.5f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd08062d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Importances (LightGBM) ===\n",
      "              feature  importance\n",
      "163         PEOE_VSA7         261\n",
      "121  FpDensityMorgan2         260\n",
      "117  MinPartialCharge         247\n",
      "132          BalabanJ         244\n",
      "205       VSA_EState8         240\n",
      "129       BCUT2D_MRHI         234\n",
      "122  FpDensityMorgan3         231\n",
      "127     BCUT2D_LOGPHI         221\n",
      "186              TPSA         216\n",
      "128    BCUT2D_LOGPLOW         215\n",
      "133           BertzCT         209\n",
      "130      BCUT2D_MRLOW         207\n",
      "120  FpDensityMorgan1         202\n",
      "204       VSA_EState7         176\n",
      "150            Kappa3         176\n",
      "\n",
      "=== Feature Importances (XGBoost) ===\n",
      "                    feature  importance\n",
      "133                 BertzCT    0.120085\n",
      "209               NHOHCount    0.106629\n",
      "230               RingCount    0.055161\n",
      "113              ExactMolWt    0.042661\n",
      "221              NumHDonors    0.040694\n",
      "186                    TPSA    0.040424\n",
      "112          HeavyAtomMolWt    0.028706\n",
      "210                 NOCount    0.021037\n",
      "55                Group_170    0.020086\n",
      "291  fr_phenol_noOrthoHbond    0.015299\n",
      "197             VSA_EState1    0.013727\n",
      "217        NumAromaticRings    0.013297\n",
      "95                Group_373    0.012516\n",
      "151               LabuteASA    0.010882\n",
      "147                     Ipc    0.010518\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance\n",
    "print(\"\\n=== Feature Importances (LightGBM) ===\")\n",
    "lgb_model = lgb.LGBMRegressor(**LGB_PARAMS)\n",
    "lgb_model.fit(X, y)\n",
    "lgb_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': lgb_model.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "print(lgb_importance.head(15))\n",
    "\n",
    "print(\"\\n=== Feature Importances (XGBoost) ===\")\n",
    "xgb_model = xgb.XGBRegressor(**XGB_PARAMS)\n",
    "xgb_model.fit(X, y)\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "print(xgb_importance.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e569388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
